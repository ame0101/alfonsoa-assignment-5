{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7v_604eN2ZXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d62410-c255-47fe-8078-c4c721942eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.spatial import cKDTree\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "BASE_PATH = \"/content/drive/My Drive/Fall 2024/CS506/HW5/\"\n",
        "TRAIN_PATH = BASE_PATH + \"train.csv\"\n",
        "TEST_PATH = BASE_PATH + \"test.csv\"\n",
        "SUBMISSION_PATH = BASE_PATH + \"submissions.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "8IIBIwTi2ZXH"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        self.tree = cKDTree(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        distances, indices = self.tree.query(X, k=self.k)\n",
        "        nearest_neighbors = self.y_train[indices]\n",
        "        predictions = np.mean(nearest_neighbors, axis=1)\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "uZCVuph72ZXH"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Identify common columns\n",
        "    common_columns = list(set(train_data.columns) & set(test_data.columns))\n",
        "    common_columns.remove('id')  # Remove 'id' if it's in common columns\n",
        "\n",
        "    # Select only common columns for both datasets\n",
        "    train_data = train_data[common_columns + ['Exited']]\n",
        "    test_data = test_data[common_columns]\n",
        "\n",
        "    # Combine train and test for preprocessing\n",
        "    all_data = pd.concat([train_data, test_data], axis=0)\n",
        "\n",
        "    # Remove non-numeric columns\n",
        "    numeric_columns = all_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_columns = ['Geography', 'Gender']\n",
        "\n",
        "    # Keep only numeric and specified categorical columns\n",
        "    columns_to_keep = numeric_columns + categorical_columns\n",
        "    all_data = all_data[columns_to_keep]\n",
        "\n",
        "    # Handle categorical variables\n",
        "    all_data = pd.get_dummies(all_data, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    all_data[numeric_columns] = scaler.fit_transform(all_data[numeric_columns])\n",
        "\n",
        "    # Split back into train and test\n",
        "    train_data = all_data[:len(train_data)]\n",
        "    test_data = all_data[len(train_data):]\n",
        "\n",
        "    # Prepare X and y for train data\n",
        "    X = train_data.drop(['Exited'], axis=1)\n",
        "    y = train_data['Exited'].astype(int)  # Ensure 'Exited' is integer\n",
        "\n",
        "    # Prepare X_test\n",
        "    X_test = test_data.drop(['Exited'], axis=1) if 'Exited' in test_data.columns else test_data\n",
        "\n",
        "    print(f\"Features in training data: {X.columns.tolist()}\")\n",
        "    print(f\"Features in test data: {X_test.columns.tolist()}\")\n",
        "\n",
        "    return X.values, y.values, X_test.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "v7bo19152ZXI"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_index, val_index in kf.split(X):\n",
        "        X_train, X_val = X[train_index], X[val_index]\n",
        "        y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "        score = roc_auc_score(y_val, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "RzeS4bZM2ZXI",
        "outputId": "02aed6fd-2fb6-4cc1-d827-27bfbb1cf370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "Features in training data: ['CreditScore', 'NumOfProducts', 'HasCrCard', 'Age', 'Balance', 'IsActiveMember', 'EstimatedSalary', 'Tenure', 'CustomerId', 'Geography_Germany', 'Geography_Spain', 'Gender_Male']\n",
            "Features in test data: ['CreditScore', 'NumOfProducts', 'HasCrCard', 'Age', 'Balance', 'IsActiveMember', 'EstimatedSalary', 'Tenure', 'CustomerId', 'Geography_Germany', 'Geography_Spain', 'Gender_Male']\n",
            "Performing cross-validation...\n",
            "Cross-validation scores: [0.8644563431112448, 0.8853093656817566, 0.8805896235980359, 0.8781554033727946, 0.8908951384784907]\n",
            "Mean CV score: 0.8798811748484645\n",
            "Starting hyperparameter tuning...\n",
            "k=3, score=0.8493372122825731\n",
            "k=5, score=0.8691206069159589\n",
            "k=7, score=0.8847654636290867\n",
            "k=9, score=0.888071205282241\n",
            "k=11, score=0.8946973131537501\n",
            "Best parameters: k=11\n",
            "Best tuning score: 0.8946973131537501\n",
            "Shape of X (training data): (15000, 12)\n",
            "Shape of X_test (test data): (10000, 12)\n",
            "Training final model...\n",
            "Making predictions...\n",
            "Submission saved to /content/drive/My Drive/Fall 2024/CS506/HW5/submissions.csv\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "print(\"Loading and preprocessing data...\")\n",
        "X, y, X_test = preprocess_data(TRAIN_PATH, TEST_PATH)\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5)\n",
        "\n",
        "# Perform cross-validation\n",
        "print(\"Performing cross-validation...\")\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV score:\", np.mean(cv_scores))\n",
        "\n",
        "# Hyperparameter tuning\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "k_values = [3, 5, 7, 9, 11]\n",
        "best_score = 0\n",
        "best_k = 0\n",
        "\n",
        "# Use a subset of data for faster tuning\n",
        "X_subset, _, y_subset, _ = train_test_split(X, y, test_size=0.7, random_state=42)\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNN(k=k)\n",
        "    scores = cross_validate(X_subset, y_subset, knn)\n",
        "    mean_score = np.mean(scores)\n",
        "    print(f\"k={k}, score={mean_score}\")\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_k = k\n",
        "\n",
        "print(f\"Best parameters: k={best_k}\")\n",
        "print(f\"Best tuning score: {best_score}\")\n",
        "\n",
        "# Print shapes before making predictions\n",
        "print(f\"Shape of X (training data): {X.shape}\")\n",
        "print(f\"Shape of X_test (test data): {X_test.shape}\")\n",
        "\n",
        "# Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "print(\"Training final model...\")\n",
        "knn = KNN(k=best_k)\n",
        "knn.fit(X, y)\n",
        "print(\"Making predictions...\")\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "test_data = pd.read_csv(TEST_PATH)\n",
        "submission = pd.DataFrame({'id': test_data['id'], 'Exited': test_predictions})\n",
        "submission.to_csv(SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"Submission saved to {SUBMISSION_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}